"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è CPU
"""

import cv2
import numpy as np
from pathlib import Path
from typing import Tuple, Optional, List, Union
import warnings
warnings.filterwarnings('ignore')

class ImageProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏"""
    
    def __init__(self, max_size: int = 1280):
        """
        Args:
            max_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        self.max_size = max_size
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è OpenCV
        cv2.setNumThreads(2)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    
    def load_image(self, image_path: Union[str, Path], optimize: bool = True) -> np.ndarray:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            optimize: –ü—Ä–∏–º–µ–Ω—è—Ç—å –ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Returns:
            np.ndarray: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        """
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ü–≤–µ—Ç–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ (BGR -> RGB)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        if optimize:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—Å–∞–π–∑ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
            image_rgb = self.auto_resize(image_rgb)
            
            # –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            image_rgb = self.enhance_for_detection(image_rgb)
        
        return image_rgb
    
    def auto_resize(self, image: np.ndarray) -> np.ndarray:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—Å–∞–π–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
        
        Args:
            image: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        
        Returns:
            np.ndarray: –†–µ—Å–∞–π–∑–Ω—É—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        """
        h, w = image.shape[:2]
        
        # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ –º–µ–Ω—å—à–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if max(h, w) <= self.max_size:
            return image
        
        # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
        if h > w:
            new_h = self.max_size
            new_w = int(w * (self.max_size / h))
        else:
            new_w = self.max_size
            new_h = int(h * (self.max_size / w))
        
        # –†–µ—Å–∞–π–∑ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–µ—Ç–∞–ª–µ–π
        resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
        
        print(f"üîÑ –ê–≤—Ç–æ-—Ä–µ—Å–∞–π–∑: {w}x{h} -> {new_w}x{new_h}")
        return resized
    
    def enhance_for_detection(self, image: np.ndarray) -> np.ndarray:
        """
        –£–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤
        
        Args:
            image: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        
        Returns:
            np.ndarray: –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced_gray = clahe.apply(gray)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ RGB
        enhanced = cv2.cvtColor(enhanced_gray, cv2.COLOR_GRAY2RGB)
        
        # –õ–µ–≥–∫–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏
        kernel = np.array([[-1, -1, -1],
                          [-1,  9, -1],
                          [-1, -1, -1]])
        sharpened = cv2.filter2D(enhanced, -1, kernel)
        
        # –°–º–µ—à–∏–≤–∞–Ω–∏–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
        alpha = 0.7
        result = cv2.addWeighted(image, alpha, sharpened, 1 - alpha, 0)
        
        return result
    
    def preprocess_for_yolo(self, image: np.ndarray, target_size: int = 640) -> np.ndarray:
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è YOLO –º–æ–¥–µ–ª–∏
        
        Args:
            image: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            target_size: –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä –¥–ª—è YOLO
        
        Returns:
            np.ndarray: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        """
        # –†–µ—Å–∞–π–∑ –¥–æ —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        h, w = image.shape[:2]
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º padding
        scale = min(target_size / h, target_size / w)
        new_h, new_w = int(h * scale), int(w * scale)
        
        # –†–µ—Å–∞–π–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ padding –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        top = (target_size - new_h) // 2
        bottom = target_size - new_h - top
        left = (target_size - new_w) // 2
        right = target_size - new_w - left
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å padding
        padded = cv2.copyMakeBorder(
            resized, top, bottom, left, right,
            cv2.BORDER_CONSTANT, value=(114, 114, 114)
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        normalized = padded.astype(np.float32) / 255.0
        
        # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å–µ–π –¥–ª—è YOLO (HWC -> CHW)
        if len(normalized.shape) == 3:
            normalized = np.transpose(normalized, (2, 0, 1))
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ batch dimension
        normalized = np.expand_dims(normalized, axis=0)
        
        return normalized
    
    def draw_detections(self, image: np.ndarray, detections: List[dict]) -> np.ndarray:
        """
        –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        
        Args:
            image: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            detections: –°–ø–∏—Å–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–π
        
        Returns:
            np.ndarray: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –æ—Ç—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏
        """
        result = image.copy()
        
        # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
        colors = {
            "person": (255, 0, 0),      # –ö—Ä–∞—Å–Ω—ã–π
            "car": (0, 255, 0),        # –ó–µ–ª–µ–Ω—ã–π
            "truck": (0, 165, 255),    # –û—Ä–∞–Ω–∂–µ–≤—ã–π
            "bus": (255, 0, 255),      # –§–∏–æ–ª–µ—Ç–æ–≤—ã–π
            "bicycle": (255, 255, 0),  # –ì–æ–ª—É–±–æ–π
            "motorcycle": (0, 255, 255) # –ñ–µ–ª—Ç—ã–π
        }
        
        for detection in detections:
            bbox = detection.get("bbox", {})
            class_name = detection.get("class", "unknown")
            confidence = detection.get("confidence", 0)
            
            if not bbox:
                continue
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
            x = int(bbox.get("x", 0))
            y = int(bbox.get("y", 0))
            width = int(bbox.get("width", 0))
            height = int(bbox.get("height", 0))
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –¥–ª—è –∫–ª–∞—Å—Å–∞
            color = colors.get(class_name, (128, 128, 128))
            
            # –†–∏—Å–æ–≤–∞–Ω–∏–µ bounding box
            cv2.rectangle(result, (x, y), (x + width, y + height), color, 2)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–µ—Ç–∫–∏
            label = f"{class_name}: {confidence:.2f}"
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ç–µ–∫—Å—Ç–∞
            font_scale = 0.5
            thickness = 1
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–µ–∫—Å—Ç–∞
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness
            )
            
            # –†–∏—Å–æ–≤–∞–Ω–∏–µ —Ñ–æ–Ω–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            cv2.rectangle(
                result,
                (x, y - text_height - baseline - 5),
                (x + text_width, y),
                color,
                -1  # –ó–∞–ª–∏–≤–∫–∞
            )
            
            # –†–∏—Å–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            cv2.putText(
                result,
                label,
                (x, y - baseline - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                font_scale,
                (255, 255, 255),  # –ë–µ–ª—ã–π —Ç–µ–∫—Å—Ç
                thickness
            )
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã GPS, –¥–æ–±–∞–≤–ª—è–µ–º –∏–∫–æ–Ω–∫—É
            if "coordinates" in detection:
                # –†–∏—Å–æ–≤–∞–Ω–∏–µ –º–∞–ª–µ–Ω—å–∫–æ–π –∏–∫–æ–Ω–∫–∏ –ª–æ–∫–∞—Ü–∏–∏
                icon_x = x + width - 20
                icon_y = y + 20
                cv2.circle(result, (icon_x, icon_y), 8, (0, 0, 255), -1)
                cv2.circle(result, (icon_x, icon_y), 5, (255, 255, 255), -1)
        
        return result
    
    def extract_frames_from_video(self, video_path: str, fps: int = 1) -> List[np.ndarray]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –∏–∑ –≤–∏–¥–µ–æ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è CPU
        
        Args:
            video_path: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É
            fps: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        
        Returns:
            List[np.ndarray]: –°–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
        """
        frames = []
        
        # –û—Ç–∫—Ä—ã—Ç–∏–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ —Ñ–∞–π–ª: {video_path}")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ FPS –≤–∏–¥–µ–æ
        video_fps = cap.get(cv2.CAP_PROP_FPS)
        frame_interval = int(video_fps / fps) if fps > 0 else 1
        
        frame_count = 0
        success = True
        
        print(f"üé• –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –∏–∑ –≤–∏–¥–µ–æ (—Ü–µ–ª–µ–≤–æ–π FPS: {fps})...")
        
        while success:
            success, frame = cap.read()
            
            if not success:
                break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä
            if frame_count % frame_interval == 0:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è BGR -> RGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞
                frame_optimized = self.auto_resize(frame_rgb)
                
                frames.append(frame_optimized)
            
            frame_count += 1
        
        cap.release()
        
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(frames)} –∫–∞–¥—Ä–æ–≤ –∏–∑ {frame_count} –≤—Å–µ–≥–æ")
        return frames
    
    def save_image(self, image: np.ndarray, output_path: Union[str, Path], 
                   quality: int = 95) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            quality: –ö–∞—á–µ—Å—Ç–≤–æ JPEG (1-100)
        
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ –ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        """
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è RGB -> BGR –¥–ª—è OpenCV
            if len(image.shape) == 3 and image.shape[2] == 3:
                image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            else:
                image_bgr = image
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º
            success = cv2.imwrite(str(output_path), image_bgr, 
                                 [cv2.IMWRITE_JPEG_QUALITY, quality])
            
            if success:
                print(f"üíæ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
            else:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {output_path}")
            
            return success
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return False
    
    def create_mosaic(self, images: List[np.ndarray], grid_size: Tuple[int, int] = (2, 2)) -> np.ndarray:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–∑–∞–∏–∫–∏ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
        Args:
            images: –°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            grid_size: –†–∞–∑–º–µ—Ä —Å–µ—Ç–∫–∏ (—Å—Ç—Ä–æ–∫–∏, –∫–æ–ª–æ–Ω–∫–∏)
        
        Returns:
            np.ndarray: –ú–æ–∑–∞–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        """
        if not images:
            raise ValueError("–°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—É—Å—Ç")
        
        rows, cols = grid_size
        max_images = rows * cols
        images_to_use = images[:max_images]
        
        # –†–µ—Å–∞–π–∑ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–æ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        target_h, target_w = 300, 400  # –†–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –º–æ–∑–∞–∏–∫–µ
        
        resized_images = []
        for img in images_to_use:
            resized = cv2.resize(img, (target_w, target_h), interpolation=cv2.INTER_AREA)
            resized_images.append(resized)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–∑–∞–∏–∫–∏
        mosaic_rows = []
        for i in range(rows):
            row_images = resized_images[i*cols:(i+1)*cols]
            
            # –ï—Å–ª–∏ –≤ —Å—Ç—Ä–æ–∫–µ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ
            while len(row_images) < cols:
                row_images.append(np.zeros((target_h, target_w, 3), dtype=np.uint8))
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å—Ç—Ä–æ–∫—É
            row = np.hstack(row_images)
            mosaic_rows.append(row)
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫
        mosaic = np.vstack(mosaic_rows)
        
        return mosaic

# –°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
image_processor = ImageProcessor()